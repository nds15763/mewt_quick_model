<!DOCTYPE html>
<!--
  Play Page - 音视频检测主页面
  
  功能：
  1. MediaPipe实时图像+音频检测
  2. Mewt四状态分类（idle/cat_visual/cat_audio/cat_both）
  3. VLM详细分析（Kimi视觉模型）
  4. RN通讯：发送检测结果文案
  
  最新改动 (2025-10-08):
  - 集成RN消息桥接（rn-bridge.js）
  - 发送完整消息格式：{type, text, source, state, timestamp, metadata}
  - 统一发送逻辑：状态变化发state，VLM返回发vlm
--><!DOCTYPE html>
<!--
本次改动简介：全面优化视频分辨率和画质，解决模糊问题
改动内容：
1. 优化摄像头分辨率约束：添加4K、2K、1080p多级分辨率选项，使用exact约束确保真实分辨率
2. 优化CSS设置：添加高DPI支持和防模糊缩放设置，确保视频不被CSS缩放模糊
3. 优化Canvas渲染：支持高DPI显示，添加设备像素比适配和高质量图像处理
4. 添加更多分辨率选项：支持从4K到1080p的多级fallback机制，确保最佳画质
目标：实现真正的1080x1920高分辨率显示，彻底解决画面模糊问题
-->
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MediaPipe Audio & Image Classification with Mewt</title>
  <style>
    /* 优化高清显示：添加高DPI支持和防模糊设置 */
    /* 改动原因：确保1080x1920高分辨率视频不被CSS缩放模糊 */
    body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: #000;
      font-family: Arial, sans-serif;
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
    }

    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      image-rendering: -webkit-optimize-contrast;
      image-rendering: crisp-edges;
    }

    #webcam {
      width: 100%;
      height: 100%;
      object-fit: cover;
      /* 高清视频优化设置 */
      image-rendering: -webkit-optimize-contrast;
      image-rendering: crisp-edges;
      image-rendering: pixelated;
      transform: translateZ(0);
      -webkit-transform: translateZ(0);
      backface-visibility: hidden;
      -webkit-backface-visibility: hidden;
    }

    #predictionPanel {
      position: absolute;
      top: 20px;
      left: 20px;
      background-color: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 15px;
      border-radius: 5px;
      z-index: 10;
      min-width: 300px;
      max-width: 500px;
    }

    #predictionPanel h3 {
      margin: 0 0 10px 0;
      font-size: 18px;
    }

    #rawPredictions {
      margin-bottom: 15px;
      font-size: 14px;
    }

    #rawPredictions pre {
      margin: 5px 0;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    #mewtResponse {
      font-size: 18px;
      min-height: 30px;
      font-weight: bold;
    }

    #loading {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      color: white;
      font-size: 24px;
      text-align: center;
    }

    .hidden {
      display: none;
    }
  </style>
</head>
<body>
  <div id="container">
    <div id="loading">Loading models...<br/><small>This may take a moment</small></div>
    <video id="webcam" autoplay playsinline></video>
    <div id="predictionPanel" class="hidden">
      <h3>Analysis Results</h3>
      <div id="rawPredictions">
        <div><strong>Image:</strong> <span id="imageResults">Analyzing...</span></div>
        <div><strong>Audio:</strong> <span id="audioResults">Analyzing...</span></div>
      </div>
      <div id="mewtResponse">Ready</div>
    </div>
  </div>

  <script type="module">
    // ========== 立即执行的消息监听器（同步，不依赖模块加载）==========
    // 在所有 import 之前设置，确保立即捕获消息，不受模块加载延迟影响
    console.log('[Play] Setting up immediate message listener');
    
    // 暂存待处理的消息
    window._pendingRNMessages = [];
    
    const immediateMessageHandler = (event) => {
      try {
        const data = typeof event.data === 'string' ? 
          JSON.parse(event.data) : event.data;
        
        console.log('[← RN Immediate]', data);
        
        // 暂存消息供后续处理
        window._pendingRNMessages.push(data);
        
      } catch (e) {
        console.error('[Play] Immediate message handler error:', e);
      }
    };
    
    // 同时监听 window 和 document（兼容 iOS/Android）
    window.addEventListener('message', immediateMessageHandler);
    document.addEventListener('message', immediateMessageHandler);
    
    console.log('[Play] Immediate message listener ready');
    
    // ========== 模块导入（会异步加载）==========
    // 显式导入 RN 消息接收器，确保尽早初始化监听器
    // 这样可以在 MewtEngine 初始化前就设置好消息监听，避免错过早期消息
    import './rn-message-receiver.js';
    
    // Import MediaPipe libraries
    import {
      ImageClassifier,
      FilesetResolver as VisionFilesetResolver
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8";
    
    import {
      AudioClassifier,
      FilesetResolver as AudioFilesetResolver
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-audio@0.10.8";
    
    // Import unified MewtEngine
    import { MewtEngine } from "./mewt-engine.js";
    
    // Import RN bridge (下行消息)
    import sendToRN from "./rn-bridge.js";

    // Get DOM elements
    const video = document.getElementById("webcam");
    const predictionPanel = document.getElementById("predictionPanel");
    const imageResultsElement = document.getElementById("imageResults");
    const audioResultsElement = document.getElementById("audioResults");
    const mewtResponseElement = document.getElementById("mewtResponse");
    const loadingElement = document.getElementById("loading");
    
    // Variables for classifiers
    let imageClassifier;
    let audioClassifier;
    let audioContext;
    let isRunning = false;
    
    // ========== 初始化统一引擎 ==========
    const engine = new MewtEngine({
      onPredictionUpdate: (data) => {
        // 引擎通知：预测结果更新
        updateDisplay(data);
      }
    });
    
    // ========== 尽早设置视频元素引用 ==========
    // 在初始化完成前就设置，这样即使模型还在加载，拍照功能也能工作
    engine.setVideoElement(video);
    console.log('[Play] Video element set early');
    
    // ========== 处理暂存的待处理消息 ==========
    // 引擎已初始化，处理之前暂存的所有消息
    if (window._pendingRNMessages && window._pendingRNMessages.length > 0) {
      console.log(`[Play] Processing ${window._pendingRNMessages.length} pending messages`);
      window._pendingRNMessages.forEach(msg => {
        engine.handleRNMessage(msg);
      });
      window._pendingRNMessages = []; // 清空队列
    }

    // Create ImageClassifier with proper error handling
    const createImageClassifier = async () => {
      try {
        console.log("Loading vision fileset...");
        const vision = await VisionFilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm"
        );
        
        console.log("Creating image classifier...");
        imageClassifier = await ImageClassifier.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/float32/1/efficientnet_lite0.tflite`
          },
          maxResults: 3,
          runningMode: "VIDEO"
        });
        
        console.log("Image classifier loaded successfully");
        return true;
      } catch (error) {
        console.error("Error loading image classifier:", error);
        loadingElement.innerHTML = "Error loading image classifier: " + error.message;
        return false;
      }
    };

    // Create AudioClassifier with proper error handling
    const createAudioClassifier = async () => {
      try {
        console.log("Loading audio fileset...");
        const audio = await AudioFilesetResolver.forAudioTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-audio@0.10.8/wasm"
        );
        
        console.log("Creating audio classifier...");
        audioClassifier = await AudioClassifier.createFromOptions(audio, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.tflite"
          },
          maxResults: 3
        });
        
        console.log("Audio classifier loaded successfully");
        return true;
      } catch (error) {
        console.error("Error loading audio classifier:", error);
        loadingElement.innerHTML = "Error loading audio classifier: " + error.message;
        return false;
      }
    };

    // 极简摄像头约束：只使用ideal值，避免OverconstrainedError
    // 改动原因：移除所有min/max和aspectRatio约束，避免过度约束导致的失败
    const startCamera = async () => {
      try {
        console.log("请求摄像头访问 (目标: 1080x1920)...");
        
        // 只使用ideal约束，完全移除min/max和aspectRatio
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: "environment" },
            width: { ideal: 1080 },
            height: { ideal: 1920 }
          }
        });
        
        video.srcObject = stream;
        
        return new Promise((resolve) => {
          video.addEventListener("playing", () => {
            setTimeout(() => {
              if (video.videoWidth > 0 && video.videoHeight > 0) {
                console.log(`✓ 摄像头就绪: ${video.videoWidth}x${video.videoHeight}`);
                resolve(true);
              } else {
                console.error("视频播放中但尺寸为0");
                resolve(false);
              }
            }, 100);
          });
        });
      } catch (err) {
        // 如果ideal约束也失败，使用完全无约束的fallback
        console.log("ideal约束失败，尝试无约束模式...");
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: true  // 完全无约束，接受任何分辨率
          });
          video.srcObject = stream;
          
          return new Promise((resolve) => {
            video.addEventListener("playing", () => {
              setTimeout(() => {
                if (video.videoWidth > 0 && video.videoHeight > 0) {
                  console.log(`✓ 摄像头就绪(fallback): ${video.videoWidth}x${video.videoHeight}`);
                  resolve(true);
                } else {
                  resolve(false);
                }
              }, 100);
            });
          });
        } catch (fallbackErr) {
          console.error("摄像头访问失败:", fallbackErr);
          loadingElement.innerHTML = "摄像头访问失败: " + fallbackErr.message;
          return false;
        }
      }
    };

    // Load models in parallel
    const loadModels = async () => {
      loadingElement.innerHTML = "Loading image classifier...<br/><small>This may take a moment</small>";
      const imageSuccess = await createImageClassifier();
      
      if (!imageSuccess) return false;
      
      loadingElement.innerHTML = "Loading audio classifier...<br/><small>This may take a moment</small>";
      const audioSuccess = await createAudioClassifier();
      
      return audioSuccess;
    };

    // Initialize: camera + models in parallel
    const initialize = async () => {
      loadingElement.innerHTML = "Starting camera...<br/><small>Please allow camera access</small>";
      
      // Start camera and load models in parallel
      const [cameraReady, modelsReady] = await Promise.all([
        startCamera(),
        loadModels()
      ]);
      
      if (!cameraReady || !modelsReady) {
        if (!modelsReady) {
          loadingElement.innerHTML = "Error loading models";
        }
        return;
      }
      
      // Hide loading indicator and show panel
      loadingElement.style.display = "none";
      // 隐藏预测面板：注释掉显示逻辑，保持面板隐藏状态
      // 改动原因：用户要求隐藏predictionPanel
      // predictionPanel.classList.remove("hidden");
      
      // 设置视频元素引用
      engine.setVideoElement(video);
      
      // Start classification
      startClassification();
    };

    // Update the display (called by engine via callback)
    const updateDisplay = (data) => {
      // Update raw predictions display
      if (data.image && data.image.length > 0) {
        const topImages = data.image.slice(0, 3);
        imageResultsElement.textContent = topImages.map(item => 
          `${item.categoryName} (${Math.round(item.score * 100)}%)`).join(', ');
      } else {
        imageResultsElement.textContent = "Analyzing...";
      }
      
      if (data.audio && data.audio.length > 0) {
        const topAudios = data.audio.slice(0, 3);
        audioResultsElement.textContent = topAudios.map(item => 
          `${item.categoryName} (${Math.round(item.score * 100)}%)`).join(', ');
      } else {
        audioResultsElement.textContent = "Analyzing...";
      }
      
      // Update Mewt response display
      mewtResponseElement.textContent = data.text;
      
      // Send to RN with complete format
      const source = data.vlmLocked ? 'vlm' : 'state';
      const metadata = {
        hasCat: data.state !== 'idle',
        hasVisual: data.hasVisual,
        hasAudio: data.hasAudio
      };
      
      // Add VLM-specific metadata
      if (data.vlmLocked) {
        metadata.confidence = 0.9;
        metadata.vlmLocked = true;
      }
      
      sendToRN(data.text, source, data.state, metadata);
    };

    // Frame rate control for image prediction
    let lastPredictionTime = 0;
    const PREDICTION_INTERVAL = 500; // 500ms = 2 frames per second
    
    // Start classification (camera already started in initialize)
    const startClassification = async () => {
      if (isRunning) return;
      isRunning = true;
      
      // Start image classification (video already playing)
      predictWebcam();
      
      // Start audio classification
      startAudioClassification();
    };

    // Predict from webcam
    const predictWebcam = async () => {
      if (!imageClassifier || !video.videoWidth || !video.videoHeight) {
        setTimeout(predictWebcam, PREDICTION_INTERVAL);
        return;
      }
      
      try {
        const now = performance.now();
        
        // Only predict if enough time has passed
        if (now - lastPredictionTime >= PREDICTION_INTERVAL) {
          lastPredictionTime = now;
          
          const classificationResult = imageClassifier.classifyForVideo(video, now);
          // 使用统一引擎处理图像结果
          engine.handleImageResult(classificationResult.classifications);
        }
      } catch (error) {
        console.error("Image classification error:", error);
      }
      
      // Continue predicting with controlled frame rate
      setTimeout(predictWebcam, PREDICTION_INTERVAL);
    };

    // Start audio classification
    const startAudioClassification = async () => {
      const constraints = { audio: true };
      let stream;

      try {
        stream = await navigator.mediaDevices.getUserMedia(constraints);
      } catch (err) {
        console.error("Error accessing microphone:", err);
        loadingElement.innerHTML = "Error accessing microphone: " + err.message;
        return;
      }

      try {
        audioContext = new AudioContext({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(stream);
        const scriptNode = audioContext.createScriptProcessor(16384, 1, 1);

        scriptNode.onaudioprocess = function (audioProcessingEvent) {
          try {
            if (!audioClassifier) return;
            
            const inputBuffer = audioProcessingEvent.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);

            // Classify the audio
            const result = audioClassifier.classify(inputData);
            // 使用统一引擎处理音频结果
            engine.handleAudioResult(result, inputData);
          } catch (error) {
            console.error("Audio classification error:", error);
          }
        };

        source.connect(scriptNode);
        scriptNode.connect(audioContext.destination);
      } catch (error) {
        console.error("Error setting up audio classification:", error);
        loadingElement.innerHTML = "Error setting up audio classification: " + error.message;
      }
    };

    
    // Initialize when page loads
    window.addEventListener("DOMContentLoaded", initialize);
  </script>
</body>
</html>
